{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbp4wqkQ4ypZrrU/BVi/TW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/git-grace/experiment/blob/main/base/preprocess_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imlgzey3ZHEK"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"i want watch movies on visha\"\n",
        "# word-type-start-end\n",
        "entities = [(\"visha\", \"App\", 23, 28)]"
      ],
      "metadata": {
        "id": "8HEC3WMrZSpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence[23:28]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uQHy1UG_Nt4e",
        "outputId": "1e76cf67-9cb0-4371-c7a4-c6812a62a6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'visha'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "2bhP-6A3ZkA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(sentence, return_offsets_mapping=True)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8DgnxrsaTuo",
        "outputId": "451d1282-c06f-4a86-dc7a-5d7c153e09ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1045, 2215, 3422, 5691, 2006, 25292, 3270, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (2, 6), (7, 12), (13, 19), (20, 22), (23, 26), (26, 28), (0, 0)]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"])\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwNEUS5tas4a",
        "outputId": "08f1c2d4-8585-4f0d-ce36-ffe5697b3148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'i', 'want', 'watch', 'movies', 'on', 'vis', '##ha', '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_entities_by_token(entity_list, token_offsets):\n",
        "  entities_by_token = []\n",
        "  edge_mismatch = False\n",
        "  start2id = {}\n",
        "  end2id = {}\n",
        "  for i, (s, e) in enumerate(token_offsets):\n",
        "    if e == 0:\n",
        "      continue\n",
        "    start2id[s] = i\n",
        "    end2id[e] = i+1\n",
        "\n",
        "  print(\"start2id: \", start2id, \"end2id: \", end2id)\n",
        "  for w, t, s, e in entity_list:\n",
        "    sid = start2id.get(s, 0)\n",
        "    eid = end2id.get(e, 0)\n",
        "    if sid and eid and (eid > sid):\n",
        "      entities_by_token.append((w, t, sid, eid))\n",
        "    else:\n",
        "      edge_mismatch = True\n",
        "    print(w, t, sid, eid)\n",
        "  return entities_by_token, edge_mismatch\n",
        "\n",
        "\n",
        "class TrainingData:\n",
        "  def __init__(self, sub_words, tokens, entities):\n",
        "    self.sub_words = sub_words\n",
        "    self.input_ids = tokens[\"input_ids\"]\n",
        "    self.length = len(tokens[\"input_ids\"])\n",
        "    self.token_type_ids = tokens[\"token_type_ids\"]\n",
        "    self.attention_mask = tokens[\"attention_mask\"]\n",
        "    self.offset_mapping = tokens[\"offset_mapping\"]\n",
        "    self.entities_tokens, self.edge_match = build_entities_by_token(entities, tokens[\"offset_mapping\"])\n",
        "\n",
        "  def get_tags(self, max_len):\n",
        "    tags = [\"O\" for _ in range(max_len)]\n",
        "    tags[0] = \"START_TAG\"\n",
        "    tags[self.length-1] = \"END_TAG\"\n",
        "    for w, t, s, e in self.entities_tokens:\n",
        "      tags[s] = f'B-{t}'\n",
        "      for j in range(s+1, e):\n",
        "        tags[j] = f\"I-{t}\"\n",
        "    return tags\n",
        "\n",
        "\n",
        "train_data = TrainingData(\n",
        "  sub_words=words,\n",
        "  tokens=tokens,\n",
        "  entities=entities,\n",
        ")\n",
        "\n",
        "tags = train_data.get_tags(max_len=10)\n",
        "for w, t in zip(words, tags):\n",
        "  print(w, t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-YP09OIauLz",
        "outputId": "78ff5355-c3a4-4f29-bb95-5e2419a572a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start2id:  {0: 1, 2: 2, 7: 3, 13: 4, 20: 5, 23: 6, 26: 7} end2id:  {1: 2, 6: 3, 12: 4, 19: 5, 22: 6, 26: 7, 28: 8}\n",
            "visha App 6 8\n",
            "[CLS] START_TAG\n",
            "i O\n",
            "want O\n",
            "watch O\n",
            "movies O\n",
            "on O\n",
            "vis B-App\n",
            "##ha I-App\n",
            "[SEP] END_TAG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def build_example(sentence_noted_list):\n",
        "  slot_value_pattern = re.compile(r'\\[(?P<value>.+?)\\]\\((?P<name>.+?)\\)', flags=re.I | re.M)\n",
        "  slot_counter = Counter()\n",
        "  data_slot_list = []\n",
        "\n",
        "  for raw in sentence_noted_list:\n",
        "    sub_sentence = []\n",
        "    slots = []\n",
        "    start_idx, act_len = 0, 0\n",
        "    for match_res in slot_value_pattern.finditer(raw):\n",
        "      raw_slot_name, raw_slot_value = match_res.group(\"name\"), match_res.group(\"value\")\n",
        "      start_pos, end_pos = match_res.start(), match_res.end()\n",
        "      print(start_pos, end_pos)\n",
        "      if start_pos > start_idx:\n",
        "        sub_sentence.append(raw[start_idx:start_pos])\n",
        "        act_len += start_pos - start_idx\n",
        "      raw_slot_value = raw_slot_value.strip()\n",
        "      sub_sentence.append(raw_slot_value)\n",
        "      _start_pos = act_len\n",
        "      act_len += len(raw_slot_value)\n",
        "      _end_pos = act_len\n",
        "      slots.append((raw_slot_value, raw_slot_name, _start_pos, _end_pos))\n",
        "      slot_counter[raw_slot_name] += 1\n",
        "      start_idx = end_pos\n",
        "    if start_idx < len(raw):\n",
        "      sub_sentence.append(raw[start_idx:])\n",
        "\n",
        "    raw_text = \"\".join(sub_sentence)\n",
        "    for slot in slots:\n",
        "      assert raw_text[slot[2]:slot[3]] == slot[0], f\"{raw_text} {slot}\"\n",
        "    data_slot_list.append((raw_text, slots))\n",
        "\n",
        "  return data_slot_list\n",
        "\n",
        "\n",
        "build_example(sentence_noted_list=[\n",
        "    \"i like eat [apple](fruit) do you like it?\",\n",
        "    \"do you want [apple](fruit) and [banana](fruit)\",\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBjf_hUVn3kJ",
        "outputId": "b3f68194-48b1-4fca-dc17-a093639242c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 25\n",
            "12 26\n",
            "31 46\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i like eat apple do you like it?', [('apple', 'fruit', 11, 16)]),\n",
              " ('do you want apple and banana',\n",
              "  [('apple', 'fruit', 12, 17), ('banana', 'fruit', 22, 28)])]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1d9T406n3tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-WxTG1kn3ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pytorch-crf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrZRLImYQ0cl",
        "outputId": "44e3910a-86ed-442e-85da-4b544dfd404a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "from itertools import repeat\n",
        "from transformers import BertModel"
      ],
      "metadata": {
        "id": "EqYN1TgaeGD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bxi6EKVZQzxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J_pn-OKJQxPS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}